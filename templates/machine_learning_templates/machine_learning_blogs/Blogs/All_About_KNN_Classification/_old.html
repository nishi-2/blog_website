<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>9c4aa0638d7c454584752ab71d10a101</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="adaa931e-2298-43a5-afc4-7f8cfd8541af" class="cell markdown">
<h2 id="introduction-to-knn"><strong>Introduction to KNN</strong></h2>
</div>
<div id="e1e08710-6177-4826-8b39-8f0b1dee680b" class="cell markdown">
<p>K-Nearest Neighbors (KNN) is a simple yet powerful algorithm that
excels at identifying patterns within data, particularly when it comes
to detecting anomalies or outliers. Because KNN compares new data points
to their closest neighbors in the feature space, it is especially
effective at flagging samples that deviate from typical patterns-making
it a common choice for outlier detection.</p>
<p>Beyond anomaly detection, KNN is widely used for both classification
and regression tasks. In classification, KNN can group items based on
similarity in their features, which makes it particularly useful in
applications such as text mining, where documents with similar word
patterns can be clustered together. For regression, KNN is well-suited
to problems where the relationship between features and the target
variable is non-linear, as it makes no assumptions about the underlying
data distribution.</p>
<p>One of the biggest advantages of KNN is its intuitiveness. It is easy
to understand and interpret, which makes it a strong candidate for
initial modeling and exploratory analysis. In fact, in certain
scenarios, especially with smaller datasets and well-separated classes,
KNN can outperform more complex machine learning models.</p>
<p>The K in KNN refers to the number of nearest neighbors the algorithm
considers when making a prediction. To understand this better, imagine
trying to decide which movie to watch next. You might ask a few of your
friends - say, 5 of them - for recommendations. If 3 out of those 5
suggest a comedy, you’re likely to choose a comedy yourself. Here, K =
5. If you had asked only 1 friend (K = 1), your decision would rely
entirely on their preference. Similarly, increasing the value of K makes
the model more generalized by considering more neighbors, while a
smaller K makes it more sensitive to noise in the data.</p>
<p>Overall, KNN remains a go-to algorithm due to its simplicity,
versatility, and effectiveness in a range of real-world applications.
However, it can be computationally expensive for large datasets, as it
requires calculating distances to all training points for each
prediction.</p>
<hr />
</div>
<div id="d61e3aab-0407-494f-89d5-d2239846a5ab" class="cell markdown">
<h2 id="distance-metric-used-in-knn"><strong>Distance Metric used in
KNN</strong></h2>
</div>
<div id="9d4c9393-72ff-417f-a67d-31adf3e9689b" class="cell markdown">
<p>At the heart of the KNN algorithm is distance measurement which is a
way to evaluate how "close" two data points are. This concept is
essential because KNN uses these distances to decide which neighbors
influence predictions.</p>
<p>Let's first understand how distances are calculated in 2D space using
Minkowski distance, then extend it to other metrics.</p>
<p>Let us consider two Points in 2D Space</p>
<ul>
<li>Point A = <span
class="math inline">(<em>x</em><sub>1</sub>,<em>y</em><sub>1</sub>)</span></li>
<li>Point B = <span
class="math inline">(<em>x</em><sub>2</sub>,<em>y</em><sub>2</sub>)</span></li>
</ul>
<ol>
<li><strong>Minkowski Distance: A Generalized Metric</strong></li>
</ol>
<p>The Minkowski distance is a generalized metric defined as:</p>
<p><span
class="math display"><em>d</em><sub><em>p</em></sub>(<em>A</em>,<em>B</em>) = (|<em>x</em><sub>1</sub>−<em>x</em><sub>2</sub>|<sup><em>p</em></sup>+|<em>y</em><sub>1</sub>−<em>y</em><sub>2</sub>|<sup><em>p</em></sup>)<sup>1/<em>p</em></sup></span></p>
<p>This formula allows you to vary the value of <span
class="math inline"><em>p</em></span>, which changes the behavior of the
distance metric. Different values of <span
class="math inline"><em>p</em></span> yield different types of
distances, each with its own geometric and practical implications.</p>
<ol>
<li><strong>When <span class="math inline"><em>p</em> = 1</span>:
Manhattan (Taxicab) Distance</strong></li>
</ol>
<p>For <span class="math inline"><em>p</em> = 1</span>, the Minkowski
formula becomes:</p>
<p><span
class="math display"><em>d</em><sub>1</sub>(<em>A</em>,<em>B</em>) = |<em>x</em><sub>1</sub>−<em>x</em><sub>2</sub>| + |<em>y</em><sub>1</sub>−<em>y</em><sub>2</sub>|</span></p>
<p>This is called Manhattan or Taxicab distance because it simulates
travel along a grid—like navigating streets in a city. You can only move
horizontally or vertically.</p>
<p>Example: If A = (2, 3) and B = (5, 7):</p>
<p><span
class="math display"><em>d</em><sub>1</sub> = |2−5| + |3−7| = 3 + 4 = 7</span></p>
<p>This distance would follow the orange path in the above diagram,
forming a right-angled route.</p>
<ol>
<li><strong>When <span class="math inline"><em>p</em> = 2</span>:
Euclidean Distance</strong></li>
</ol>
<p>The most commonly used metric is when <span
class="math inline"><em>p</em> = 2</span>:</p>
<p><span class="math display">$$
d_2(A, B) = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}
$$</span></p>
<p>This gives the straight-line distance, like how a bird would fly
directly from one point to another. The formula replicates Pythagoras
Theorem.</p>
<p>Example: Using A = (2, 3) and B = (5, 7):</p>
<p><span class="math display">$$
d_2 = \sqrt{(3)^2 + (4)^2} = \sqrt{9 + 16} = 5
$$</span></p>
<ol>
<li><strong>When <span class="math inline"><em>p</em> → ∞</span>:
Chebyshev Distance</strong></li>
</ol>
<p>As <span class="math inline"><em>p</em></span> approaches infinity,
the Minkowski distance becomes:</p>
<p><span
class="math display"><em>d</em><sub>∞</sub>(<em>A</em>,<em>B</em>) = max (|<em>x</em><sub>1</sub>−<em>x</em><sub>2</sub>|, |<em>y</em><sub>1</sub>−<em>y</em><sub>2</sub>|)</span></p>
<p>This is the Chebyshev distance, often used in games like chess where
a move can span diagonals, rows, or columns—all in one step.</p>
<p>Example: A = (2, 3), B = (5, 7):</p>
<p><span
class="math display"><em>d</em><sub>∞</sub> = max (3,4) = 4</span></p>
<p>It captures the largest directional change between two points.</p>
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/ecc61ae3-d689-4cfb-8fa0-1ca9088e8377.png"
alt="image.png" /></p>
<hr />
<h3 id="why-does-the-value-of-p-matter-in-knn"><strong>Why Does the
Value of <span class="math inline"><em>p</em></span> Matter in
KNN?</strong></h3>
<p>The choice of <span class="math inline"><em>p</em></span> influences
how distances are interpreted:</p>
<ul>
<li><span class="math inline"><em>p</em> = 1</span>: Treats all
directional changes equally. Useful when data follows grid
patterns.</li>
<li><span class="math inline"><em>p</em> = 2</span>: Captures geometric
distance. Ideal when spatial or physical distance matters.</li>
<li><span class="math inline"><em>p</em> → ∞</span>: Focuses only on the
largest change. Helpful in some pathfinding or board game logic.</li>
</ul>
<p>KNN performance can vary significantly based on the distance metric.
Cross-validation can help you select the best <span
class="math inline"><em>p</em></span> for your dataset.</p>
<hr />
<h3 id="other-important-distance-metrics-in-knn"><strong>Other Important
Distance Metrics in KNN</strong></h3>
<p>While Minkowski metrics are common, other specialized distances are
also widely used in machine learning:</p>
<ol>
<li><strong>Mahalanobis Distance</strong></li>
</ol>
<p>Measures the distance between points while considering the variance
and correlation between features. It is given by -</p>
<p><span class="math display">$$
D_M(x, y) = \sqrt{(x - y)^T S^{-1} (x - y)}
$$</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline"><em>x</em></span> and <span
class="math inline"><em>y</em></span> are vectors (points)</li>
<li><span class="math inline"><em>S</em></span> is the covariance matrix
of the dataset</li>
<li><span class="math inline"><em>S</em><sup>−1</sup></span> is its
inverse</li>
</ul>
<p>If features are correlated or have different scales, Mahalanobis
adjusts for that. It scales the space so that variances become equal and
uncorrelated - giving a more true sense of distance. More
computationally intensive due to inversion of covariance matrix. It is
ideal to use when features are interrelated. Often used in Outlier
detection, in data with correlated features and for Multivariate
analysis.</p>
<ol>
<li><strong>Cosine Similarity and Distance</strong></li>
</ol>
<p>Measures the angle between vectors rather than magnitude. Focuses on
direction, not magnitude.</p>
<p><span class="math display">$$
\text{Cosine Similarity} = \frac{x \cdot y}{\|x\| \|y\|}
$$</span></p>
<p>Cosine <strong>distance</strong> is simply:</p>
<p><span class="math display">Cosine Distance = 1 − Cosine
Similarity</span></p>
<p>Two vectors pointing in the same direction have cosine similarity 1,
and those at 90° have similarity 0. It is great for high-dimensional
sparse data like text. It doesn't work well for purely numeric
regression tasks. It is best for Text mining, Document clustering,
Sparse data with high dimensions (e.g., TF-IDF vectors).</p>
<ol>
<li><strong>Hamming Distance</strong></li>
</ol>
<p>Hamming distance counts the number of positions at which the
corresponding symbols differ between two strings of equal length.</p>
<p><span class="math display">$$
\text{Hamming Distance} = \sum_{i=1}^n \mathbb{1}(x_i \ne y_i)
$$</span></p>
<p>Where <span class="math inline">𝟙</span> is an indicator
function.</p>
<p>It's a simple count of mismatches and is ideal for binary or
categorical data. It works only for discrete valued equal length
vectors. It is fast and efficient for binary data and is not suited for
continuous variables. It is generally used in DNA sequence comparison,
Error detection in transmission (parity checks) and in case of using KNN
for categorical attributes (e.g., gender, color, type).</p>
<ol>
<li><strong>Jaccard Distance</strong></li>
</ol>
<p>Used to compare set similarity based on intersection and union.</p>
<p><span class="math display">$$
\text{Jaccard Similarity} = \frac{|A \cap B|}{|A \cup B|}, \quad
\text{Jaccard Distance} = 1 - \text{Jaccard Similarity}
$$</span></p>
<p>It measures how similar two sets are based on shared vs total unique
elements. It is used only for sets or binary-encoded features (e.g., tag
vectors). It is very effective for sparse binary data. Usually used in
Recommender systems, Set-based feature encoding, Tag or attribute
matching.</p>
<hr />
<p>Selecting the right distance metric is crucial in KNN. It determines
which neighbors influence the model, which in turn impacts predictions.
The more aligned the metric is with the nature of the data, the better
KNN algorithm will perform.</p>
<hr />
</div>
<div id="7bb58eb1-1437-47dd-bcf7-6c87bf6a5875" class="cell markdown">
<h2 id="knn-as-a-classifier-demo"><strong>KNN as a Classifier
demo</strong></h2>
</div>
<div id="7cdc896b-b5bb-4e23-ae8a-22a36be5fddc" class="cell code"
data-execution_count="1">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code></pre></div>
</div>
<div id="853f7748-3f7b-4d91-8c35-6929a5c13230" class="cell markdown">
<p>Let us use randomly generated data for the purpose. We will use
make_blobs from sklearn datasets and what it does is generates normally
distributed points around a specified center. This function will return
2 arrays -</p>
<ul>
<li>First array stores the coordinates</li>
<li>Second array stores the corresponding labels</li>
</ul>
</div>
<div id="cf4e65a8-a842-43cb-9dc7-9a68e441c612" class="cell code"
data-execution_count="2">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span></code></pre></div>
</div>
<div id="1bf07da2-265c-4571-92c9-955269d518f7" class="cell code"
data-execution_count="3">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>inputs, targets <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">1000</span>, centers<span class="op">=</span>[(<span class="op">-</span><span class="dv">6</span>,<span class="dv">6</span>), (<span class="op">-</span><span class="dv">3</span>,<span class="dv">2</span>), (<span class="op">-</span><span class="dv">6</span>,<span class="dv">4</span>)] , random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Centers is defining the center around which points will be centered - here we gave 3 so target will have 3 labels</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># You can also write integer numbers to get desired labels, that is centers = 5 will give you 5 different labels</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># You can control the number of features to include by n_features parameter</span></span></code></pre></div>
</div>
<div id="742a48c1-51c9-476a-96b4-f06f6e95e047" class="cell code"
data-execution_count="4">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>inputs[:<span class="dv">2</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<pre><code>array([[-4.97593747,  4.59252695],
       [-4.33874079,  3.54290374]])</code></pre>
</div>
</div>
<div id="cab87f1c-a961-4194-bc68-ead3bc8140f9" class="cell code"
data-execution_count="5">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>targets[:<span class="dv">2</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<pre><code>array([2, 2])</code></pre>
</div>
</div>
<div id="b1297f12-2fd2-4369-886d-93d23204fea4" class="cell code"
data-execution_count="6">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>inputs.shape   <span class="co"># 1000 rows and 2 coordinates x and y which is equivalent to 2 features</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="6">
<pre><code>(1000, 2)</code></pre>
</div>
</div>
<div id="860f7362-fd37-4e97-af18-cf7e8d5adb98" class="cell code"
data-execution_count="7">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s create a pandas dataframe with the newly created data points</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> inputs, columns <span class="op">=</span> [<span class="st">&#39;feature1&#39;</span>, <span class="st">&#39;feature2&#39;</span>])</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;target&#39;</span>] <span class="op">=</span> targets</span></code></pre></div>
</div>
<div id="89e50bcc-a142-42e6-a8c7-c34cc9074566" class="cell code"
data-execution_count="8">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="8">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature1</th>
      <th>feature2</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-4.975937</td>
      <td>4.592527</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-4.338741</td>
      <td>3.542904</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-7.607483</td>
      <td>6.184634</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-4.923993</td>
      <td>4.021312</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-6.756351</td>
      <td>4.577746</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="79525c1c-8349-469f-90d1-633eac95763e" class="cell code"
data-execution_count="9">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;target&#39;</span>].value_counts()</span></code></pre></div>
<div class="output execute_result" data-execution_count="9">
<pre><code>target
0    334
2    333
1    333
Name: count, dtype: int64</code></pre>
</div>
</div>
<div id="0f8f83a2-b91d-480e-b254-32e882b38ecf" class="cell markdown">
<h4 id="visualize-the-dataset">Visualize the dataset</h4>
</div>
<div id="81aeeced-45ca-42b2-8d2e-3272f3064bac" class="cell code"
data-execution_count="10">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x <span class="op">=</span> <span class="st">&#39;feature1&#39;</span>, y <span class="op">=</span> <span class="st">&#39;feature2&#39;</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                data <span class="op">=</span> data,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                hue <span class="op">=</span> <span class="st">&#39;target&#39;</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>                palette <span class="op">=</span> [<span class="st">&#39;#000172&#39;</span>, <span class="st">&#39;#287281&#39;</span>, <span class="st">&#39;#986732&#39;</span>],</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>                style <span class="op">=</span> <span class="st">&#39;target&#39;</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>                s <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/67c655190d05facb424a11e335cb92137b7b4049.png" /></p>
</div>
</div>
<div id="70688875-a66f-4cc2-a144-b86758d408bb" class="cell markdown">
<p>To look at the normal distribution of data, we can use the jointplot
from sns -</p>
</div>
<div id="8aab703d-d74f-41fe-b73d-75af623e4a53" class="cell code"
data-execution_count="11">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>sns.jointplot(x <span class="op">=</span> <span class="st">&#39;feature1&#39;</span>, y <span class="op">=</span> <span class="st">&#39;feature2&#39;</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>              data <span class="op">=</span> data,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>              hue <span class="op">=</span> <span class="st">&#39;target&#39;</span>,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>              palette <span class="op">=</span> [<span class="st">&#39;#000172&#39;</span>, <span class="st">&#39;#287281&#39;</span>, <span class="st">&#39;#986732&#39;</span>],</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>              height<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>              s <span class="op">=</span> <span class="dv">60</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>             )</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/16795a28f9e9fb2b889ea29c611d928d27bd9809.png" /></p>
</div>
</div>
<div id="23cfca87-b755-494c-adb7-fa0053be5230" class="cell markdown">
<p>So, we generated random points and distributed amongst three classes.
Now we will use these points to train KNN Algorithm. Before that, we
need to split our data.</p>
</div>
<div id="4cb57b81-6670-4767-bdea-07b5d9392b6a" class="cell markdown">
<h4 id="splitting-data-into-train-and-test">Splitting data into train
and test</h4>
</div>
<div id="3a7dcb62-430a-40c9-9729-c6aa006474d0" class="cell code"
data-execution_count="12">
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(data.iloc[:, :<span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>                                                    data.iloc[:, <span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>                                                    random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>x_train.shape, x_test.shape, y_train.shape, y_test.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="12">
<pre><code>((800, 2), (200, 2), (800,), (200,))</code></pre>
</div>
</div>
<div id="958f3456-bc75-497e-854f-3d2c0a00c414" class="cell code"
data-execution_count="13">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>x_train.head(<span class="dv">2</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature1</th>
      <th>feature2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>29</th>
      <td>-1.469249</td>
      <td>3.218762</td>
    </tr>
    <tr>
      <th>535</th>
      <td>-6.883857</td>
      <td>6.153725</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="dfb7119c-7a36-46bb-80bb-10f30b907fa7" class="cell markdown">
<h4 id="building-the-model">Building the model</h4>
</div>
<div id="b926c214-4602-4ba6-afca-352d3e23a3e1" class="cell code"
data-execution_count="14">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsClassifier</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s instantiate the model with 1 neighbor at first</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> KNeighborsClassifier(n_neighbors <span class="op">=</span> <span class="dv">1</span>)  <span class="co"># By default, the value of this parameter is 5</span></span></code></pre></div>
</div>
<div id="2f2e25ba-4f75-4b3e-bc5a-c880da98324f" class="cell code"
data-execution_count="15">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>clf.fit(x_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div> </div></div></div></div>
</div>
</div>
<div id="b710c561-2c35-46b2-83ca-49080700a33c" class="cell code"
data-execution_count="16">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>samples <span class="op">=</span> [[<span class="op">-</span><span class="fl">3.6</span>, <span class="dv">3</span>], [<span class="op">-</span><span class="fl">7.6</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="fl">2.15</span>, <span class="fl">2.7</span>]]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>sample_set <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> samples, columns<span class="op">=</span>[<span class="st">&#39;feature1&#39;</span>, <span class="st">&#39;feature2&#39;</span>])</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>sample_set</span></code></pre></div>
<div class="output execute_result" data-execution_count="16">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>feature1</th>
      <th>feature2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-3.60</td>
      <td>3.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-7.60</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-2.15</td>
      <td>2.7</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div id="7bda98fa-70e1-4f90-8cd0-b4418822fb7c" class="cell code"
data-execution_count="17">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>prediction <span class="op">=</span> clf.predict(sample_set)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>prediction</span></code></pre></div>
<div class="output execute_result" data-execution_count="17">
<pre><code>array([1, 2, 1])</code></pre>
</div>
</div>
<div id="a9017f0c-d1bc-4533-9f6b-70c976d28c54" class="cell markdown">
<p>It shows that the data point belongs to label 2. Let's retrieve the
nearest neighbor of this point.</p>
</div>
<div id="a2d3fb7d-00f1-47ab-9508-67091529d041" class="cell code"
data-execution_count="18">
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>neighbors <span class="op">=</span> clf.kneighbors(sample_set)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>neighbors</span></code></pre></div>
<div class="output execute_result" data-execution_count="18">
<pre><code>(array([[0.06855388],
        [0.44865184],
        [0.19497333]]),
 array([[750],
        [777],
        [509]], dtype=int64))</code></pre>
</div>
</div>
<div id="d32734b1-babd-4af5-9769-bd1880d4a843" class="cell markdown">
<p>The result is tuple of arrays -</p>
<ul>
<li>First array stores the Euclidean distance from the new points in
sample set to its nearest neighbor points from training set.</li>
<li>Second array stores the index of the neighbor points as in the
training dataset.</li>
</ul>
<p>Let's visualize this.</p>
</div>
<div id="e393cdd3-a05c-4130-b168-1b57bfc7832f" class="cell code"
data-execution_count="19">
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">14</span>,<span class="dv">5</span>))</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x <span class="op">=</span> x_train.iloc[:, <span class="dv">0</span>], y <span class="op">=</span> x_train.iloc[:, <span class="dv">1</span>],</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                hue <span class="op">=</span> y_train,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                palette <span class="op">=</span> [<span class="st">&#39;#000172&#39;</span>, <span class="st">&#39;#287281&#39;</span>, <span class="st">&#39;#986732&#39;</span>],</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>                s <span class="op">=</span> <span class="dv">60</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>                legend <span class="op">=</span> <span class="va">True</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>sns.scatterplot(x <span class="op">=</span> sample_set.iloc[:, <span class="dv">0</span>], y <span class="op">=</span> sample_set.iloc[:, <span class="dv">1</span>],</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>                markers <span class="op">=</span> [<span class="st">&#39;o&#39;</span>],</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>                color <span class="op">=</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>                s <span class="op">=</span> <span class="dv">30</span>,</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>                legend <span class="op">=</span> <span class="va">False</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>               )</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/cc65f3cac886615af983b36e4cd116165497bffe.png" /></p>
</div>
</div>
<div id="cfd12a77-2593-45ff-8b4c-c5bf7ccd8b99" class="cell markdown">
<p>Red points shows the new points and the neighbours nearest to it.
Sometimes, a new point may get assigned to a certain label which is not
as close to the new point as some other label might be. For example a
new point maybe close to class 2 but the prediction shows that its close
to class 1. Why is the case? Let's check the weight of the model first
-</p>
</div>
<div id="14043f70-36f8-43d3-b7b4-9904d712878d" class="cell code"
data-execution_count="20">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>clf.get_params()</span></code></pre></div>
<div class="output execute_result" data-execution_count="20">
<pre><code>{&#39;algorithm&#39;: &#39;auto&#39;,
 &#39;leaf_size&#39;: 30,
 &#39;metric&#39;: &#39;minkowski&#39;,
 &#39;metric_params&#39;: None,
 &#39;n_jobs&#39;: None,
 &#39;n_neighbors&#39;: 1,
 &#39;p&#39;: 2,
 &#39;weights&#39;: &#39;uniform&#39;}</code></pre>
</div>
</div>
<div id="6d780cf5-a975-4bf0-9671-cefbab343634" class="cell markdown">
<p>By default, the weights parameter in KNN is set to uniform. This
means all neighbors contribute equally to the classification, regardless
of how close or far they are from the point being predicted. As a
result, when there is a tie between classes - for example, if one
neighbor belongs to class 1 and another to class 2 - the classifier is
equally likely to choose either class.</p>
<p>However, in practice, the classifier doesn't make a random choice in
the event of a tie. It consistently picks the class with the smaller
label, no matter how many times you run the classifier. Why does this
happen?</p>
<p>To understand this, we need to look at how the predict method is
implemented. Internally, it uses the mode function from the scipy.stats
library to determine the most frequent class among the nearest
neighbors. When there's a tie (i.e., multiple classes appear the same
number of times), the mode function returns the smallest value among
them.</p>
<p>So if both class 1 and class 2 occur once, the classifier will always
return class 1, simply because it has a lower numerical label. This
happens even if class 2 is represented by a neighbor that is closer to
the input point than the one from class 1.</p>
<p>This behavior is a bit counterintuitive, especially for an algorithm
like KNN, which is fundamentally based on distance. In such cases, it
makes more sense to give more weight to closer neighbors.</p>
<p>To improve this, we can change the weights parameter from uniform to
distance. When this setting is used, each neighbor's influence is
determined by how close it is to the input point. Specifically, each
neighbor gets a weight equal to the inverse of its distance:</p>
<p><span class="math display">$$
\text{weight}_i = \frac{1}{\text{distance}_i}
$$</span></p>
<p>This means that neighbors closer to the query point have a greater
impact on the prediction, while those farther away contribute less.
Using distance weighting helps the model make decisions that better
reflect the true structure of the data, especially in cases of ties or
when neighbor distances vary significantly.</p>
</div>
<div id="a18023db-df83-4171-a5cb-a84fcc941c34" class="cell code"
data-execution_count="21">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s run the model code again</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>clf2 <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">1</span>, weights<span class="op">=</span><span class="st">&#39;distance&#39;</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>clf2.fit(x_train, y_train)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>prediction2 <span class="op">=</span> clf2.predict(sample_set)</span></code></pre></div>
</div>
<div id="1bb7be0f-545e-417f-833f-e2c89db9f9af" class="cell code"
data-execution_count="22">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>clf2.get_params()</span></code></pre></div>
<div class="output execute_result" data-execution_count="22">
<pre><code>{&#39;algorithm&#39;: &#39;auto&#39;,
 &#39;leaf_size&#39;: 30,
 &#39;metric&#39;: &#39;minkowski&#39;,
 &#39;metric_params&#39;: None,
 &#39;n_jobs&#39;: None,
 &#39;n_neighbors&#39;: 1,
 &#39;p&#39;: 2,
 &#39;weights&#39;: &#39;distance&#39;}</code></pre>
</div>
</div>
<div id="7ab5a22d-ee64-47c1-b464-dc845026fef0" class="cell code"
data-execution_count="23">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>prediction2</span></code></pre></div>
<div class="output execute_result" data-execution_count="23">
<pre><code>array([1, 2, 1])</code></pre>
</div>
</div>
<div id="d2c8373c-3411-4f99-b59a-2ca7ca38a30d" class="cell code"
data-execution_count="24">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>prediction</span></code></pre></div>
<div class="output execute_result" data-execution_count="24">
<pre><code>array([1, 2, 1])</code></pre>
</div>
</div>
<div id="57cc0e99-f2a9-4d49-a5d7-7199ebdc80f2" class="cell markdown">
<p>In many situations, using uniform weights in KNN works well and is
often preferred, especially when the data is evenly distributed and
relatively clean. With uniform weights, every neighbor contributes
equally to the classification, which simplifies the model and can
prevent overfitting to local noise or outliers. However, this approach
might not always capture the influence of proximity, especially in more
complex or noisy datasets.</p>
</div>
<div id="1efe5b60-8312-496b-8f78-ffda31d750bf" class="cell markdown">
<h4 id="understanding-decision-boundaries">Understanding decision
boundaries</h4>
<p>To better understand the impact of KNN parameters - particularly the
choice of k, the number of neighbors - it helps to visualize how the
algorithm behaves in feature space. One effective way to do this is by
constructing decision boundaries or decision regions.</p>
<p>Decision boundaries show the areas in the feature space where the
classifier assigns different class labels. Each region corresponds to
one class, and any new point that falls within a region will be
classified accordingly. These boundaries shift depending on how k is set
and whether uniform or distance-based weighting is used.</p>
<p>When k is small (such as 1 or 3), the decision boundaries are more
sensitive to individual data points. This can lead to overfitting, where
the model captures noise and makes overly complex boundaries. As k
increases, the model becomes more stable and generalizes better,
resulting in smoother and more averaged decision boundaries. However, if
k is too large, the model may become too simple, potentially
misclassifying points near the edge of a cluster.</p>
<p>By plotting decision regions for different values of k, we can
observe how the model behaves and choose a value that best balances bias
and variance. These visualizations help identify how robust the
classifier is to variations in the data and how much influence local
neighbors have on predictions.</p>
<p>Visual tools like decision boundary plots allow us to better
understand and fine-tune the classifier for optimal performance on
different datasets.</p>
</div>
<div id="4b99d8c5-887f-4731-95b6-bb60f1b562e4" class="cell code"
data-execution_count="25">
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlxtend.plotting <span class="im">import</span> plot_decision_regions</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span></code></pre></div>
</div>
<div id="78bc27bf-62ad-48d7-ac82-a077ac1529ef" class="cell code"
data-execution_count="26">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>plot_decision_regions(X <span class="op">=</span> np.array(x_train), </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>                      y <span class="op">=</span> np.array(y_train),</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>                      X_highlight <span class="op">=</span> np.array(sample_set),</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>                      clf <span class="op">=</span> clf2, </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>                      scatter_kwargs<span class="op">=</span> {<span class="st">&#39;s&#39;</span>:<span class="dv">60</span>, <span class="st">&#39;edgecolor&#39;</span>:<span class="st">&#39;white&#39;</span>, <span class="st">&#39;alpha&#39;</span>:<span class="fl">0.5</span>},</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>                      legend <span class="op">=</span> <span class="va">True</span>)  </span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="co"># This function requires 2D array - (samples, features) and labels</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>E:\7. Deep Learning\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/6504eacb2b880ad39d24a220e7e58dbf71cd783f.png" /></p>
</div>
</div>
<div id="2d3fd501-d2d5-48a3-8ba0-c46a18c5fe79" class="cell markdown">
<p>Coloured sections are the decision region, and the boundaries that
separates them are the decision boundaries. This plot visually explains
how KNN partitions the feature space into different class regions based
on proximity to labeled training samples. The decision boundaries curve
around clusters and adapt to the distribution of data points, making KNN
a flexible but non-parametric classifier.</p>
<p>K value of 1 is not really a good choice. The model is very flexible
and creates decision boundaries that are unique to each training
dataset. Thus, introducing even a new single data can change boundaries
a lot. Model will likely overfit during training and will have poor
performance on the new datasets. This kind of model will have low bias
and high variance.</p>
</div>
<div id="4aa21998-01ef-4bb4-b1f7-994572134d48" class="cell markdown">
<p>Let's try with higher value of k and see what happens. It will take
few seconds -</p>
</div>
<div id="7ea6d2ce-004a-43d5-925d-ef22db62b311" class="cell code"
data-execution_count="27">
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>clf3 <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span><span class="dv">30</span>, weights<span class="op">=</span><span class="st">&#39;uniform&#39;</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>clf3.fit(x_train, y_train)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>prediction3 <span class="op">=</span> clf3.predict(sample_set)</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>plot_decision_regions(X <span class="op">=</span> np.array(x_train), </span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>                      y <span class="op">=</span> np.array(y_train),</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>                      X_highlight <span class="op">=</span> np.array(sample_set),</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>                      clf <span class="op">=</span> clf3, </span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>                      scatter_kwargs<span class="op">=</span> {<span class="st">&#39;s&#39;</span>:<span class="dv">60</span>, <span class="st">&#39;edgecolor&#39;</span>:<span class="st">&#39;white&#39;</span>, <span class="st">&#39;alpha&#39;</span>:<span class="fl">0.5</span>},</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>                      legend <span class="op">=</span> <span class="va">True</span>) </span></code></pre></div>
<div class="output stream stderr">
<pre><code>E:\7. Deep Learning\venv\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(
</code></pre>
</div>
<div class="output execute_result" data-execution_count="27">
<pre><code>&lt;Axes: &gt;</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/67ddbe46a1734b5e1b4b1ba3663a28a0a5601b41.png" /></p>
</div>
</div>
<div id="dd542f9c-25a1-463e-b4b5-24294575abc9" class="cell markdown">
<p>Decision boundaries have changed quiet a lot. Some greens have also
got misclassified. This model may suffer from underfitting where we get
low variance but high bias. So, we need to find the value of K which is
the most optimal to use.</p>
<p>One way to analyze value of k is to get the number of misclassified
test data points as the value of K increases. This metric is called
misclassification rate, which is defined as -
<code>Misclassification rate = 1 - accuracy</code>. We can also refer it
as Error Rate.</p>
</div>
<div id="a893f611-8612-4f3d-b219-943ea95bd7a2" class="cell markdown">
<h4 id="getting-error-rates-from-a-set-of-models">Getting error rates
from a set of models</h4>
</div>
<div id="54b74e03-2d04-463d-994c-aafd50886e6c" class="cell code"
data-execution_count="28">
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>error_uniform <span class="op">=</span> []  <span class="co"># Stores error rates from models with uniformly distributed weights</span></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>error_distance <span class="op">=</span> []   <span class="co"># Stores error rates from models with distance-based weights</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>):</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k, weights<span class="op">=</span><span class="st">&#39;uniform&#39;</span>)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(x_test)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    error_uniform.append(<span class="dv">1</span> <span class="op">-</span> accuracy_score(y_test, predictions))</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> KNeighborsClassifier(n_neighbors<span class="op">=</span>k, weights<span class="op">=</span><span class="st">&#39;distance&#39;</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(x_test)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    error_distance.append(<span class="dv">1</span> <span class="op">-</span> accuracy_score(y_test, predictions))</span></code></pre></div>
</div>
<div id="38921ea6-c463-4094-9960-71ca44319fc4" class="cell code"
data-execution_count="31">
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s plot now</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>), error_uniform, c <span class="op">=</span> <span class="st">&#39;red&#39;</span>, linestyle <span class="op">=</span> <span class="st">&#39;solid&#39;</span>,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, markerfacecolor <span class="op">=</span> <span class="st">&#39;black&#39;</span>, label <span class="op">=</span> <span class="st">&#39;Error Uniform&#39;</span>)</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>), error_distance, c <span class="op">=</span> <span class="st">&#39;purple&#39;</span>, linestyle <span class="op">=</span> <span class="st">&#39;--&#39;</span>,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, markerfacecolor <span class="op">=</span> <span class="st">&#39;white&#39;</span>, label <span class="op">=</span> <span class="st">&#39;Error Distance&#39;</span>)</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;K values&#39;</span>)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Error rate&#39;</span>)</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/09d6e7d3572e7acc647cb9b8d51d08d898f40ea7.png" /></p>
</div>
</div>
<div id="432d8ffe-a8fb-40e0-849d-5ed842d0dbdf" class="cell markdown">
<p>Now from the above we will select a value of k which is not very
small to introduce high variance and not very large to introduce high
bias. It must also cause small error rate. On an average, from above we
can see that uniform weights works better than distance based weights.
Now there are multiple values of k which shows small error rate. Which
one to choose? We will use GridSearchCV for the purpose.</p>
</div>
<div id="d85b82cf-37f8-4c8c-87d6-7523dded26ef" class="cell markdown">
<h4 id="using-gridsearchcv">Using GridSearchCV</h4>
</div>
<div id="8b865c6a-32cd-48fa-b235-2971b909450f" class="cell code"
data-execution_count="32">
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>grid_params <span class="op">=</span> {</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;n_neighbors&#39;</span> : <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>),</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;weights&#39;</span> : [<span class="st">&#39;uniform&#39;</span>, <span class="st">&#39;distance&#39;</span>]</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>gridcv <span class="op">=</span> GridSearchCV(estimator <span class="op">=</span> KNeighborsClassifier(),</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>                      param_grid<span class="op">=</span>grid_params,</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>                      scoring<span class="op">=</span><span class="st">&#39;accuracy&#39;</span>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>gridcv.fit(x_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="32">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(estimator=KNeighborsClassifier(),
             param_grid={&#x27;n_neighbors&#x27;: range(1, 31),
                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},
             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" ><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(estimator=KNeighborsClassifier(),
             param_grid={&#x27;n_neighbors&#x27;: range(1, 31),
                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},
             scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" ><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: KNeighborsClassifier</label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(n_neighbors=8)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" ><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(n_neighbors=8)</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<div id="400c752c-00ac-464e-9123-cd5b1d346bd0" class="cell code"
data-execution_count="33">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>gridcv.best_params_</span></code></pre></div>
<div class="output execute_result" data-execution_count="33">
<pre><code>{&#39;n_neighbors&#39;: 8, &#39;weights&#39;: &#39;uniform&#39;}</code></pre>
</div>
</div>
<div id="ebd660fe-7e11-4530-96b2-1af8b7ac5f9d" class="cell markdown">
<p>GridSearch has returned uniform to be the best weight and neighbors
as 8 to the optimal in our case.</p>
</div>
<div id="f3a8030a-d7d5-4dda-8e83-8468e45581b2" class="cell code"
data-execution_count="34">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>gridcv.best_estimator_</span></code></pre></div>
<div class="output execute_result" data-execution_count="34">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox" checked><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(n_neighbors=8)</pre></div> </div></div></div></div>
</div>
</div>
<div id="37dda47c-c150-4f07-b8e4-a42fb120a460" class="cell code"
data-execution_count="35">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>gridcv.best_score_   </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This number is a mean of all accuracies obtained during cross validation process</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="35">
<pre><code>0.8625</code></pre>
</div>
</div>
<div id="7e16bfb7-4304-4dde-aba0-afa7d9860f5c" class="cell code"
data-execution_count="36">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> gridcv.best_estimator_</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>clf.fit(x_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="36">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsClassifier(n_neighbors=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox" checked><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsClassifier<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html">?<span>Documentation for KNeighborsClassifier</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsClassifier(n_neighbors=8)</pre></div> </div></div></div></div>
</div>
</div>
<div id="e807a56d-8758-4230-8eb1-47bd6ea0f5a1" class="cell code"
data-execution_count="37">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> clf.predict(x_test)</span></code></pre></div>
</div>
<div id="e4f47945-ce44-4d02-8454-7403c9ad5f51" class="cell markdown">
<h4 id="evaluating-model-performance">Evaluating Model performance</h4>
</div>
<div id="c0e6b5ad-c087-4e4e-b829-640871730b58" class="cell code"
data-execution_count="38">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking the score</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>accuracy_score(predictions, y_test)</span></code></pre></div>
<div class="output execute_result" data-execution_count="38">
<pre><code>0.86</code></pre>
</div>
</div>
<div id="4d1efaa5-b978-4d20-886a-dd329b8ea1dd" class="cell markdown">
<p>As we know accuracy is not the best metric to use for classification
tasks. So let's use other metrics for classification -</p>
</div>
<div id="dc56652f-da8d-4bf2-bf51-18345dc5ae79" class="cell code"
data-execution_count="39">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report, confusion_matrix</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>cnf_matrix <span class="op">=</span> confusion_matrix(predictions, y_test)</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>cnf_matrix</span></code></pre></div>
<div class="output execute_result" data-execution_count="39">
<pre><code>array([[65,  0, 15],
       [ 1, 52,  3],
       [ 8,  1, 55]], dtype=int64)</code></pre>
</div>
</div>
<div id="dee37b74-5d5a-43ef-8744-5c6c0f9c34a2" class="cell code"
data-execution_count="40">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">5</span>))</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>sns.heatmap(</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>    cnf_matrix,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>    annot<span class="op">=</span><span class="va">True</span>,               <span class="co"># Show numbers in cells</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>    fmt<span class="op">=</span><span class="st">&#39;d&#39;</span>,                  <span class="co"># Format numbers as integers</span></span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>    cmap<span class="op">=</span><span class="st">&#39;magma&#39;</span>,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>    xticklabels<span class="op">=</span>clf.classes_,</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>    yticklabels<span class="op">=</span>clf.classes_</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Predicted Label&#39;</span>)</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;True Label&#39;</span>)</span>
<span id="cb56-13"><a href="#cb56-13" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Confusion Matrix&#39;</span>)</span>
<span id="cb56-14"><a href="#cb56-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/0881784a64000a54f981fe84288b622ed688f250.png" /></p>
</div>
</div>
<div id="42d07cd1-f911-4f02-841b-3b492c789b83" class="cell code"
data-execution_count="42">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(predictions, y_test))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>              precision    recall  f1-score   support

           0       0.88      0.81      0.84        80
           1       0.98      0.93      0.95        56
           2       0.75      0.86      0.80        64

    accuracy                           0.86       200
   macro avg       0.87      0.87      0.87       200
weighted avg       0.87      0.86      0.86       200

</code></pre>
</div>
</div>
<div id="5b6ae9a8-1645-46e0-8c81-52a402927506" class="cell markdown">
<p>The classification report shows an overall accuracy of 86%,
indicating that the model correctly classified 86% of all test
instances.</p>
<ul>
<li><p>Class 1 achieved the best performance with a precision of 0.98,
recall of 0.93, and F1-score of 0.95, suggesting it is predicted with
high confidence and completeness.</p></li>
<li><p>Class 0 also performed well with a precision of 0.88 and F1-score
of 0.84, though its recall (0.81) is slightly lower.</p></li>
<li><p>Class 2 has the weakest metrics, particularly in precision
(0.75), meaning the model often misclassifies other classes as class 2.
However, it has a decent recall of 0.86.</p></li>
</ul>
<p>The macro and weighted averages are balanced at around 0.87,
confirming that the model maintains fairly consistent performance across
classes, though there is room for improvement in class 2's
precision.</p>
</div>
<div id="53471c21-a68a-48f7-85ba-31660ffc44e9" class="cell markdown">
<hr />
</div>
<div id="f41be9a6-a04e-4215-85df-24ba30fea259" class="cell markdown">
<h2 id="knn-as-a-regressor-demo"><strong>KNN as a Regressor
demo</strong></h2>
</div>
<div id="b9ee3dbc-9878-4b54-b6b9-76f0068bbdbc" class="cell markdown">
<p>Mechanics of this algorithm is same as that of KNN Classifier, just
used for regression task. Aim here is to not create an accurate model
but to show how this algorithm works.</p>
</div>
<div id="0378550b-e07e-4fc4-9382-1493d0f7c484" class="cell code"
data-execution_count="43">
<div class="sourceCode" id="cb59"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span></code></pre></div>
</div>
<div id="65034ac0-e4b0-4a6b-9c0d-d2c480582e45" class="cell markdown">
<p>Here we will draw random data points from a linear regression with a
single feature and a single output. This will be easier to visualize for
us.</p>
</div>
<div id="69fe28e3-8d58-46c4-bd09-78c090203a4b" class="cell code"
data-execution_count="49">
<div class="sourceCode" id="cb60"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>inputs, targets <span class="op">=</span> make_regression(n_samples <span class="op">=</span> <span class="dv">10</span>, n_features<span class="op">=</span> <span class="dv">1</span>, noise <span class="op">=</span> <span class="dv">6</span>,</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>                                 random_state <span class="op">=</span> <span class="dv">42</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># noise if to deviate the data point that is to introduce a bit of noise in linear data</span></span></code></pre></div>
</div>
<div id="0bf8df3e-629e-4fe6-ab73-25d9c9f147cd" class="cell code"
data-execution_count="50">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(inputs, targets)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/8751e62273aea933052a0ab3f0421fee865fc908.png" /></p>
</div>
</div>
<div id="7f24eeea-024f-45d3-8faf-3e49bef730ef" class="cell markdown">
<p>This is the linear dataset with some noise. Target values or y axis
shows numbers that varies a lot. Let's divide the values by the max
value.</p>
</div>
<div id="125e8732-9d15-414a-9ae0-4fa9f80938a3" class="cell code"
data-execution_count="51">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> targets<span class="op">/</span>targets.<span class="bu">max</span>()</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(inputs, targets)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/c77848649420908f703806b92c437c98b9f3c871.png" /></p>
</div>
</div>
<div id="f6b9d787-7745-4fb4-b14b-65f0ba36781e" class="cell markdown">
<p>Great! Now we will create the model.</p>
</div>
<div id="5089b95b-90e8-440e-a980-bb30c2a93f35" class="cell code"
data-execution_count="52">
<div class="sourceCode" id="cb63"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>reg_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>reg_knn</span></code></pre></div>
<div class="output execute_result" data-execution_count="52">
<style>#sk-container-id-5 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-5 {
  color: var(--sklearn-color-text);
}

#sk-container-id-5 pre {
  padding: 0;
}

#sk-container-id-5 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-5 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-5 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-5 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-5 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-5 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-5 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-5 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-5 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-5 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-5 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-5 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-5 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-5 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-5 div.sk-label label.sk-toggleable__label,
#sk-container-id-5 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-5 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-5 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-5 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-5 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-5 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-5 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-5 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-5 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-5 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-5 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-5" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsRegressor(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator  sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox" checked><label for="sk-estimator-id-7" class="sk-toggleable__label  sk-toggleable__label-arrow ">&nbsp;&nbsp;KNeighborsRegressor<a class="sk-estimator-doc-link " rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html">?<span>Documentation for KNeighborsRegressor</span></a><span class="sk-estimator-doc-link ">i<span>Not fitted</span></span></label><div class="sk-toggleable__content "><pre>KNeighborsRegressor(n_neighbors=1)</pre></div> </div></div></div></div>
</div>
</div>
<div id="e80566a4-dc72-4ebd-8069-453a2d352442" class="cell code"
data-execution_count="53">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>reg_knn.fit(inputs, targets)</span></code></pre></div>
<div class="output execute_result" data-execution_count="53">
<style>#sk-container-id-6 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-6 {
  color: var(--sklearn-color-text);
}

#sk-container-id-6 pre {
  padding: 0;
}

#sk-container-id-6 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-6 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-6 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-6 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-6 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-6 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-6 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-6 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-6 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-6 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-6 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-6 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-6 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-6 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-6 div.sk-label label.sk-toggleable__label,
#sk-container-id-6 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-6 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-6 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-6 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-6 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-6 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-6 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-6 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-6 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-6 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-6 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-6" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>KNeighborsRegressor(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox" checked><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;KNeighborsRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html">?<span>Documentation for KNeighborsRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>KNeighborsRegressor(n_neighbors=1)</pre></div> </div></div></div></div>
</div>
</div>
<div id="3cdb9316-76a5-4e33-8d50-5e85a80f0a09" class="cell code"
data-execution_count="70">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>x_pred <span class="op">=</span> <span class="fl">0.53</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> reg_knn.predict([[x_pred]])</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>y_pred</span></code></pre></div>
<div class="output execute_result" data-execution_count="70">
<pre><code>array([-0.08901495])</code></pre>
</div>
</div>
<div id="06818966-7c04-4ff0-a121-5cb45eeae532" class="cell code"
data-execution_count="71">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>neighbors_reg <span class="op">=</span> reg_knn.kneighbors([[x_pred]])</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>neighbors_reg</span></code></pre></div>
<div class="output execute_result" data-execution_count="71">
<pre><code>(array([[0.01256004]]), array([[5]], dtype=int64))</code></pre>
</div>
</div>
<div id="07ede1df-c3e9-403f-8212-1cdd5e56bf3c" class="cell markdown">
<p>This shows the same values as it is in Classification, just the
difference is that the first array gives a value in x axis. Let's plot
to see -</p>
</div>
<div id="f8254c0c-4cac-4935-b625-2e3b67630492" class="cell code"
data-execution_count="72">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>plt.scatter(inputs, targets)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_pred, y_pred)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/8b9970cb0dd5ced4cd49b592fc61366d6163e6a8.png" /></p>
</div>
</div>
<div id="5179e022-eb6f-4d0e-9e40-dc40ff672fdf" class="cell markdown">
<p>As per above, the nearest output is at index 5. Let's check the value
at index 5 and compare with our predicted value -</p>
</div>
<div id="c1443925-f64a-409e-b1fe-a3ae4f8bba25" class="cell code"
data-execution_count="75">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>y_pred, targets[<span class="dv">5</span>]  <span class="co"># They are almost the same</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="75">
<pre><code>(array([-0.08901495]), -0.08901494592896088)</code></pre>
</div>
</div>
<div id="86cdde44-488e-4bbc-9b30-9ff364ffd1f1" class="cell markdown">
<p>In KNN regression, when <code>k = 1</code>, the predicted value of
the target variable <span class="math inline"><em>ŷ</em></span> is
simply the target value of the nearest neighbor. However, when the value
of <code>k</code> is increased to a number greater than 1, the
prediction is no longer based on a single point but instead on the
average of the target values of the <strong>k</strong> nearest
neighbors.</p>
<p>For example, if <code>k = 3</code>, the algorithm identifies the 3
closest data points to the query instance, retrieves their corresponding
target values, and computes their average. This average becomes the
predicted output for the query point.</p>
<p><strong>General Formula for KNN Regression:</strong></p>
<p>Let the <strong>k</strong> nearest neighbors to a point <span
class="math inline"><em>x</em></span> be <span
class="math inline"><em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>k</em></sub></span>,
with corresponding target values <span
class="math inline"><em>y</em><sub>1</sub>, <em>y</em><sub>2</sub>, …, <em>y</em><sub><em>k</em></sub></span>.
Then, the predicted value <span class="math inline"><em>ŷ</em></span> is
given by:</p>
<p><span class="math display">$$
\hat{y} = \frac{1}{k} \sum_{i=1}^{k} y_i
$$</span></p>
<p>This approach allows the prediction to be more stable and less
sensitive to noise, especially when compared to using only the single
nearest neighbor. If we use <strong>distance-based weighting</strong>,
the prediction formula adjusts to give closer neighbors more
influence.</p>
</div>
<div id="42ea7efb-5f59-472e-b6d8-6b5fd0e841b5" class="cell code"
data-execution_count="82">
<div class="sourceCode" id="cb72"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s change k to 4 and see what we get</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="#cb72-3" aria-hidden="true" tabindex="-1"></a>reg_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span><span class="dv">4</span>)</span>
<span id="cb72-4"><a href="#cb72-4" aria-hidden="true" tabindex="-1"></a>reg_knn.fit(inputs, targets)</span>
<span id="cb72-5"><a href="#cb72-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-6"><a href="#cb72-6" aria-hidden="true" tabindex="-1"></a>x_pred <span class="op">=</span> <span class="fl">0.53</span></span>
<span id="cb72-7"><a href="#cb72-7" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> reg_knn.predict([[x_pred]])</span>
<span id="cb72-8"><a href="#cb72-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-9"><a href="#cb72-9" aria-hidden="true" tabindex="-1"></a>plt.scatter(inputs, targets)</span>
<span id="cb72-10"><a href="#cb72-10" aria-hidden="true" tabindex="-1"></a>plt.scatter(x_pred, y_pred)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/5c583a7d58d9d275d08817ee452e558c2ef86103.png" /></p>
</div>
</div>
<div id="6378eafb-cebd-4ff2-bf56-b5accd538803" class="cell code"
data-execution_count="86">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>neighbors <span class="op">=</span> reg_knn.kneighbors([[x_pred]])</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>neighbors</span></code></pre></div>
<div class="output execute_result" data-execution_count="86">
<pre><code>(array([[0.01256004, 0.03328585, 0.11768854, 0.23743473]]),
 array([[5, 6, 9, 2]], dtype=int64))</code></pre>
</div>
</div>
<div id="63328a7e-c337-4fbb-9bc3-cb54c4871f66" class="cell code"
data-execution_count="92">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>(targets[<span class="dv">5</span>] <span class="op">+</span> targets[<span class="dv">6</span>] <span class="op">+</span> targets[<span class="dv">9</span>] <span class="op">+</span> targets[<span class="dv">2</span>])<span class="op">/</span><span class="dv">4</span></span></code></pre></div>
<div class="output execute_result" data-execution_count="92">
<pre><code>0.06162155187861659</code></pre>
</div>
</div>
<div id="414ecf22-fa23-461f-8f4a-70f187c93430" class="cell code"
data-execution_count="90">
<div class="sourceCode" id="cb77"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>y_pred</span></code></pre></div>
<div class="output execute_result" data-execution_count="90">
<pre><code>array([0.06162155])</code></pre>
</div>
</div>
<div id="2910d5b2-358c-4c11-9dee-9dc1a40513ee" class="cell markdown">
<p>Exactly the same just as the formula says.</p>
<p>Now let's compare the parametric and non parametric approaches.</p>
</div>
<div id="65b977f6-2e82-4052-87eb-ab745dfefeb4" class="cell markdown">
<hr />
</div>
<div id="49c93d7a-aeae-4373-984f-69458984487f" class="cell markdown">
<h2
id="comparison-of-knn-regressor-with-linear-regression"><strong>Comparison
of KNN Regressor with Linear Regression</strong></h2>
</div>
<div id="bb73871f-3c24-4241-a2f3-8872a1eefbca" class="cell markdown">
<p>Parametric approaches refer to algorithms that make strong
assumptions about the form or structure of the data. A common example is
linear regression, which assumes that the relationship between the
independent and dependent variables is linear. In such a model,
increasing the input by one unit results in a fixed, proportional change
in the output. While this makes the model simple, interpretable, and
computationally efficient, it is also quite restrictive and may not work
well when the true relationship is more complex or non-linear.</p>
<p>On the other hand, non-parametric approaches like KNN make no
assumptions about the underlying data distribution. KNN adapts to the
shape and structure of the data by using the target values of nearby
points to make predictions. This flexibility makes it a good choice when
the form of the relationship between variables is not known in advance
or is highly irregular.</p>
<p>Given this, one might wonder why linear regression is still widely
used. The answer lies in the trade-off between simplicity and
flexibility. Linear regression tends to perform well when the true
relationship is approximately linear or when interpretability is a
priority. It also requires less data to train effectively and can
extrapolate to unseen regions of the feature space. KNN, while more
flexible, may require a large amount of data, can be sensitive to noise,
and struggles with extrapolation. In the end, the choice depends on the
nature of the dataset and the specific goals of the analysis.</p>
<p>Let's see here how it works -</p>
</div>
<div id="f0c6ae91-be2e-4f9c-af2f-6c38366072d2" class="cell markdown">
<p>Let's define data first.</p>
</div>
<div id="74cffebb-b146-431a-9a6f-b9bc1f0a5c85" class="cell code"
data-execution_count="96">
<div class="sourceCode" id="cb79"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>inputs, targets <span class="op">=</span> make_regression(n_samples <span class="op">=</span> <span class="dv">500</span>,</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>                                  n_features<span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>                                  noise <span class="op">=</span> <span class="dv">28</span>,</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>                                  random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>targets <span class="op">=</span> targets<span class="op">/</span>targets.<span class="bu">max</span>()</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>plt.scatter(inputs, targets, color <span class="op">=</span> <span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Targets&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/198ccc492607fca88cd7e9fd0e545318ad40808e.png" /></p>
</div>
</div>
<div id="b8e71d06-7c1a-43df-8d5f-50249e654b69" class="cell code"
data-execution_count="130">
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Splitting the dataset</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(inputs, targets,</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>                                                    test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code></pre></div>
</div>
<div id="9301858c-75a1-4873-842b-99c2dfc692b3" class="cell code"
data-execution_count="131">
<div class="sourceCode" id="cb81"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_train, y_train, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Training Data&#39;</span>)</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x_test, y_test, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;Test Data&#39;</span>)</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/58b587b70d6f5e134b7b2480ca4abdf99d5f67b9.png" /></p>
</div>
</div>
<div id="fc1a80ac-d131-4e4b-a9a9-e08becf4696b" class="cell markdown">
<p>Now, let's perform linear and KNN regression</p>
</div>
<div id="6abc662c-c80c-43ea-9e0d-9a96120dc42c" class="cell code"
data-execution_count="132">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> KNeighborsRegressor</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>grid_knn <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>KNeighborsRegressor(),</span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>                       param_grid<span class="op">=</span> {</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&#39;n_neighbors&#39;</span> : <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>),</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&#39;weights&#39;</span> : [<span class="st">&#39;distance&#39;</span>, <span class="st">&#39;uniform&#39;</span>]</span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>                       },</span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>                       scoring<span class="op">=</span><span class="st">&#39;neg_mean_squared_error&#39;</span>)</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>grid_knn.fit(x_train, y_train)</span></code></pre></div>
<div class="output execute_result" data-execution_count="132">
<style>#sk-container-id-13 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-13 {
  color: var(--sklearn-color-text);
}

#sk-container-id-13 pre {
  padding: 0;
}

#sk-container-id-13 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-13 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-13 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-13 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-13 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-13 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-13 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-13 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-13 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-13 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-13 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-13 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-13 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-13 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-13 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-13 div.sk-label label.sk-toggleable__label,
#sk-container-id-13 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-13 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-13 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-13 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-13 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-13 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-13 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-13 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-13 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-13 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-13 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-13 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-13" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GridSearchCV(estimator=KNeighborsRegressor(),
             param_grid={&#x27;n_neighbors&#x27;: range(1, 31),
                         &#x27;weights&#x27;: [&#x27;distance&#x27;, &#x27;uniform&#x27;]},
             scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox" ><label for="sk-estimator-id-23" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;GridSearchCV<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html">?<span>Documentation for GridSearchCV</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>GridSearchCV(estimator=KNeighborsRegressor(),
             param_grid={&#x27;n_neighbors&#x27;: range(1, 31),
                         &#x27;weights&#x27;: [&#x27;distance&#x27;, &#x27;uniform&#x27;]},
             scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-24" type="checkbox" ><label for="sk-estimator-id-24" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">best_estimator_: KNeighborsRegressor</label><div class="sk-toggleable__content fitted"><pre>KNeighborsRegressor(n_neighbors=15)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-25" type="checkbox" ><label for="sk-estimator-id-25" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;KNeighborsRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsRegressor.html">?<span>Documentation for KNeighborsRegressor</span></a></label><div class="sk-toggleable__content fitted"><pre>KNeighborsRegressor(n_neighbors=15)</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<div id="c91cd8be-8ea8-41b4-8d43-36905ea4d14d" class="cell code"
data-execution_count="133">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a>grid_knn.best_estimator_, grid_knn.best_score_</span></code></pre></div>
<div class="output execute_result" data-execution_count="133">
<pre><code>(KNeighborsRegressor(n_neighbors=15), -0.013154379819456791)</code></pre>
</div>
</div>
<div id="c662d2d0-6247-420c-a45a-cf1e9d01d5d0" class="cell markdown">
<p>This means our model, on average, makes squared errors of around
0.0131 between predicted and actual target values.</p>
</div>
<div id="5e8c0b34-eb35-4135-81ad-229f5fc09de7" class="cell code"
data-execution_count="134">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s fit KNN Regressor model with this best estimator and initiate Linear Regression</span></span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>reg_linear <span class="op">=</span> LinearRegression()</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>reg_linear.fit(x_train, y_train)</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a>linear_prediction <span class="op">=</span> reg_linear.predict(x_test)</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-7"><a href="#cb85-7" aria-hidden="true" tabindex="-1"></a>reg_knn <span class="op">=</span> grid_knn.best_estimator_</span>
<span id="cb85-8"><a href="#cb85-8" aria-hidden="true" tabindex="-1"></a>reg_knn.fit(x_train, y_train)</span>
<span id="cb85-9"><a href="#cb85-9" aria-hidden="true" tabindex="-1"></a>knn_prediction <span class="op">=</span> reg_knn.predict(x_test)</span></code></pre></div>
</div>
<div id="7710193e-99e6-4bb3-b00c-3e2f1d5d6fc5" class="cell code"
data-execution_count="135">
<div class="sourceCode" id="cb86"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-3"><a href="#cb86-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb86-4"><a href="#cb86-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_test, y_test, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb86-5"><a href="#cb86-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test, linear_prediction)</span>
<span id="cb86-6"><a href="#cb86-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Fit with Linear Regression&#39;</span>)</span>
<span id="cb86-7"><a href="#cb86-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb86-8"><a href="#cb86-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb86-9"><a href="#cb86-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-10"><a href="#cb86-10" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb86-11"><a href="#cb86-11" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x_test, y_test, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb86-12"><a href="#cb86-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(x_test, knn_prediction)</span>
<span id="cb86-13"><a href="#cb86-13" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;Fit with KNN Regressor&#39;</span>)</span>
<span id="cb86-14"><a href="#cb86-14" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb86-15"><a href="#cb86-15" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb86-16"><a href="#cb86-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb86-17"><a href="#cb86-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/ac8b662752dbc332a71aefd501c96b622f94f5d0.png" /></p>
</div>
</div>
<div id="d96e4729-ad2b-4388-9d39-22373e02a9d8" class="cell markdown">
<p>For KNN, we see jagged or uneven line instead of a smooth straight
line because:</p>
<p>KNN Regressor is non-parametric and non-linear. It doesn't learn a
global equation (like linear regression does). Instead, it:</p>
<ul>
<li>Predicts the target for each test point based on local averages of
k-nearest neighbors</li>
<li>This causes the prediction line to zigzag or appear step-like,
especially when k is small or the test points are not sorted</li>
</ul>
</div>
<div id="b1b563d4-2d26-4358-ad22-cd7af2d3d7b7" class="cell markdown">
<p>Let's now see how it looks with sorted values and we will try with 3
different k values</p>
</div>
<div id="c076dba3-4ddd-4d2a-80c5-38a0be10ce6b" class="cell code"
data-execution_count="138">
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a>y_pred_knn <span class="op">=</span> []</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">1</span>,<span class="dv">10</span>,<span class="dv">40</span>]:</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> KNeighborsRegressor(n_neighbors<span class="op">=</span>i)</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>    model.fit(x_train, y_train)</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    y_pred_knn.append(model.predict(x_test))</span></code></pre></div>
</div>
<div id="69368cde-fa39-436c-8bad-5c20598ae0b7" class="cell code"
data-execution_count="140" data-scrolled="true">
<div class="sourceCode" id="cb88"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> {</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;x_test&#39;</span> : <span class="bu">list</span>(x_test.flatten()),</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_test&#39;</span> : <span class="bu">list</span>(y_test.flatten()),</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_pred_linear&#39;</span> : <span class="bu">list</span>(linear_prediction.flatten()),</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_pred_knn_cv&#39;</span> : <span class="bu">list</span>(knn_prediction.flatten()),</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_pred_knn_1&#39;</span> : <span class="bu">list</span>(y_pred_knn[<span class="dv">0</span>].flatten()),</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_pred_knn_10&#39;</span> : <span class="bu">list</span>(y_pred_knn[<span class="dv">1</span>].flatten()),</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;y_pred_knn_40&#39;</span> : <span class="bu">list</span>(y_pred_knn[<span class="dv">2</span>].flatten()),</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>                 )</span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sort_values(by <span class="op">=</span> [<span class="st">&#39;x_test&#39;</span>])</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>x_test_sorted <span class="op">=</span> df[<span class="st">&#39;x_test&#39;</span>].to_list()</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a>y_test_sorted <span class="op">=</span> df[<span class="st">&#39;y_test&#39;</span>].to_list()</span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a>y_pred_linear_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_linear&#39;</span>].to_list()</span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a>y_pred_knn_cv_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn_cv&#39;</span>].to_list()</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a>y_pred_knn_1_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn_1&#39;</span>].to_list()</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a>y_pred_knn_10_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn_10&#39;</span>].to_list()</span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a>y_pred_knn_40_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn_40&#39;</span>].to_list()</span></code></pre></div>
</div>
<div id="28bb2f7d-a174-4730-9b0f-6429e5519b6d" class="cell code"
data-execution_count="143">
<div class="sourceCode" id="cb89"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb89-2"><a href="#cb89-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb89-3"><a href="#cb89-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb89-4"><a href="#cb89-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_test_sorted, y_test_sorted, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb89-5"><a href="#cb89-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test_sorted, y_pred_linear_sorted)</span>
<span id="cb89-6"><a href="#cb89-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Fit with Linear Regression&#39;</span>)</span>
<span id="cb89-7"><a href="#cb89-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb89-8"><a href="#cb89-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Targets&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/246ecd94bf2d334542cc907c6b20bd0aa8df47ff.png" /></p>
</div>
</div>
<div id="afe3999c-e2b2-46ec-b5c7-735284bd47c3" class="cell code"
data-execution_count="151">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">21</span>, <span class="dv">6</span>))  </span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">1</span>)</span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_test_sorted, y_test_sorted, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test_sorted, y_pred_knn_1_sorted, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;KNN Regression (k=1)&#39;</span>)</span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a>ax2 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x_test_sorted, y_test_sorted, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a>ax2.plot(x_test_sorted, y_pred_knn_10_sorted, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;KNN Regression (k=10)&#39;</span>)</span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>ax3 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">3</span>)</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>ax3.scatter(x_test_sorted, y_test_sorted, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>ax3.plot(x_test_sorted, y_pred_knn_40_sorted, color<span class="op">=</span><span class="st">&#39;blue&#39;</span>)</span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>ax3.set_title(<span class="st">&#39;KNN Regression (k=40)&#39;</span>)</span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>ax3.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>ax3.set_ylabel(<span class="st">&#39;Targets&#39;</span>)</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/afd1a8116d897e02594a65208ef168d53f0e1e44.png" /></p>
</div>
</div>
<div id="ab44710e-10d1-4223-8144-20e97af72772" class="cell code"
data-execution_count="149">
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">4</span>))</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> fig.add_subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_test_sorted, y_test_sorted, color<span class="op">=</span><span class="st">&#39;#934421&#39;</span>)</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test_sorted, y_pred_knn_cv_sorted)</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Fit with KNN Regression&#39;</span>)</span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Features&#39;</span>)</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Targets&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/831da1fbd9c4b25717740322ec283580adca8eed.png" /></p>
</div>
</div>
<div id="1c984bb0-fc2a-44af-9ae8-cf27f1c829c6" class="cell markdown">
<p>This graph shows the best fit with our data. Let's now calculate the
error.</p>
</div>
<div id="e26b7491-4156-4429-af20-1e2cc0e12fe4" class="cell code"
data-execution_count="152">
<div class="sourceCode" id="cb92"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a>linear_reg_error <span class="op">=</span> mean_squared_error(y_test, linear_prediction)</span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a>knn_reg_error <span class="op">=</span> mean_squared_error(y_test, knn_prediction)</span></code></pre></div>
</div>
<div id="b2e3869b-2ea5-40a3-928a-6d55af655b54" class="cell code"
data-execution_count="153">
<div class="sourceCode" id="cb93"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a>linear_reg_error</span></code></pre></div>
<div class="output execute_result" data-execution_count="153">
<pre><code>0.010253765593013877</code></pre>
</div>
</div>
<div id="e5293061-2723-44b2-a75e-59933ae73de0" class="cell code"
data-execution_count="154">
<div class="sourceCode" id="cb95"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>knn_reg_error</span></code></pre></div>
<div class="output execute_result" data-execution_count="154">
<pre><code>0.010670577903965932</code></pre>
</div>
</div>
<div id="da8c4c8b-6ca2-4c7e-8bf7-af78eb18e878" class="cell markdown">
<p>Error is almost the same for our data. For datasets that exhibit a
clear linear relationship between features and target values, both
linear regression and KNN regression can provide similar levels of
accuracy. However, in such cases, linear regression is often a better
choice. This is because linear regression is a parametric model that
assumes a specific form for the relationship between variables, allowing
it to capture the underlying trend efficiently with fewer data points.
In contrast, KNN regression is non-parametric and relies on local
patterns in the data. It may not effectively capture the overall trend,
especially when predicting values outside the range of the training
data. KNN also requires a larger dataset to perform well and struggles
with extrapolation, where linear regression can still produce reasonable
predictions based on the learned coefficients. Therefore, when the true
relationship is known to be linear, linear regression often provides
more reliable and interpretable results.</p>
</div>
<div id="89c0351e-c48b-40e1-a54b-8f839ca35212" class="cell markdown">
<hr />
</div>
<div id="f6950357-ba14-401d-b8ea-86065293300b" class="cell markdown">
<h2
id="cases-when-knn-regressor-can-work-better-than-linear-regression"><strong>Cases
when KNN Regressor can work better than Linear Regression</strong></h2>
</div>
<div id="357123cb-fb86-4fe2-9fa9-669cc893c5b8" class="cell markdown">
<p>Here, we will write a <code>non_linear_regression</code> function
that generates a <strong>synthetic non-linear regression
dataset</strong>. It creates input features <code>x</code> and
corresponding target values <code>y</code> based on a <strong>non-linear
relationship</strong> that includes a <strong>quadratic</strong> and a
<strong>sinusoidal</strong> component, plus optional <strong>Gaussian
noise</strong>.</p>
<ul>
<li>uni = lambda n : np.random.uniform(-2, 2, n) - Generates
<code>n</code> uniformly distributed random numbers between -2 and
2.</li>
<li>add_noise = lambda n : np.random.normal(0, 1, n) - Generates
<code>n</code> values from a standard normal distribution (mean=0,
std=1) to be used as noise.</li>
<li>y = y_raw + noise * np.std(y_raw) * add_noise(n_samples) - Adds
Gaussian noise scaled by:
<ul>
<li><code>noise</code> factor</li>
<li>Standard deviation of <code>y_raw</code> So that noise is relative
to the signal's variation.</li>
</ul></li>
</ul>
</div>
<div id="1e892359-dbc4-42d3-bdf0-9512422668ea" class="cell code"
data-execution_count="157">
<div class="sourceCode" id="cb97"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> sin</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a function that generates a random non-linear dataset</span></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> non_linear_regression(n_samples, noise <span class="op">=</span> <span class="dv">0</span>, random_state <span class="op">=</span> <span class="va">None</span>):</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> random_state:</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>        np.random.seed(random_state)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a>    uni <span class="op">=</span> <span class="kw">lambda</span> n : np.random.uniform(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, n)</span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    add_noise <span class="op">=</span>  <span class="kw">lambda</span>  n : np.random.normal(<span class="dv">0</span>, <span class="dv">1</span>, n)</span>
<span id="cb97-11"><a href="#cb97-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-12"><a href="#cb97-12" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> []</span>
<span id="cb97-13"><a href="#cb97-13" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> uni(n_samples)</span>
<span id="cb97-14"><a href="#cb97-14" aria-hidden="true" tabindex="-1"></a>    x.sort()</span>
<span id="cb97-15"><a href="#cb97-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb97-16"><a href="#cb97-16" aria-hidden="true" tabindex="-1"></a>    y_raw <span class="op">=</span> [i<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> sin(<span class="dv">5</span><span class="op">*</span>i) <span class="cf">for</span> i <span class="kw">in</span> x]</span>
<span id="cb97-17"><a href="#cb97-17" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> y_raw <span class="op">+</span> noise <span class="op">*</span> np.std(y_raw) <span class="op">*</span> add_noise(n_samples)</span>
<span id="cb97-18"><a href="#cb97-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb97-19"><a href="#cb97-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x, y</span></code></pre></div>
</div>
<div id="0b7065c9-d684-4443-ad14-e315e7f8bc97" class="cell code"
data-execution_count="161" data-scrolled="true">
<div class="sourceCode" id="cb98"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data without noise</span></span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>inputs_no_noise, target_no_noise <span class="op">=</span> non_linear_regression(<span class="dv">300</span>, <span class="dv">0</span>, <span class="dv">42</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Using the same random state as above, generate the data with some noise</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a>inputs, target <span class="op">=</span> non_linear_regression(<span class="dv">300</span>, <span class="fl">0.5</span>, <span class="dv">42</span>)</span></code></pre></div>
</div>
<div id="103c4c06-1720-46d2-860a-9c013233007c" class="cell code"
data-execution_count="162">
<div class="sourceCode" id="cb99"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">4</span>))</span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a>ax1.scatter(inputs_no_noise, target_no_noise, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Data without noise&#39;</span>)</span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Target&#39;</span>)</span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a>ax2.scatter(inputs, target, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb99-11"><a href="#cb99-11" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;Data with noise&#39;</span>)</span>
<span id="cb99-12"><a href="#cb99-12" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb99-13"><a href="#cb99-13" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Target&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/6172178ecf8b0bafdc6d391e03f23bf8d17daeb1.png" /></p>
</div>
</div>
<div id="cc483c5f-6928-4883-bd80-e510accfbbc5" class="cell markdown">
<p>Noise is introduced to make it a bit complicated.</p>
</div>
<div id="7ed70f42-6e3a-423f-9cdb-712cfc9c224a" class="cell code"
data-execution_count="163">
<div class="sourceCode" id="cb100"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(inputs, </span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>                                                    target, </span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>                                                    test_size <span class="op">=</span> <span class="fl">0.2</span>, </span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>                                                    random_state <span class="op">=</span> <span class="dv">42</span>)</span></code></pre></div>
</div>
<div id="13bbb0c5-1b0d-490c-8ac3-1a93f6c751a9" class="cell code"
data-execution_count="165">
<div class="sourceCode" id="cb101"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-3"><a href="#cb101-3" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">13</span>,<span class="dv">4</span>))</span>
<span id="cb101-4"><a href="#cb101-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-5"><a href="#cb101-5" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_train, y_train, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb101-6"><a href="#cb101-6" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Training data&#39;</span>)</span>
<span id="cb101-7"><a href="#cb101-7" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb101-8"><a href="#cb101-8" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Target&#39;</span>)</span>
<span id="cb101-9"><a href="#cb101-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb101-10"><a href="#cb101-10" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x_test, y_test, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb101-11"><a href="#cb101-11" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;Test data&#39;</span>)</span>
<span id="cb101-12"><a href="#cb101-12" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb101-13"><a href="#cb101-13" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Target&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/d65828c718ad4d89dbcdbbd6759739f944fd542b.png" /></p>
</div>
</div>
<div id="a2510393-f153-4617-a6e9-35424b83e63e" class="cell markdown">
<p>Now let's fit linear regression and multiple KNN regression</p>
</div>
<div id="8e4894d7-5c23-4302-883c-e24a6d30a59e" class="cell code"
data-execution_count="166">
<div class="sourceCode" id="cb102"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>reg_lin <span class="op">=</span> LinearRegression()</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-3"><a href="#cb102-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb102-4"><a href="#cb102-4" aria-hidden="true" tabindex="-1"></a><span class="co"># In sklearn, when fitting data with only 1 feature, the following reshaping should be applied.</span></span>
<span id="cb102-5"><a href="#cb102-5" aria-hidden="true" tabindex="-1"></a>reg_lin.fit(x_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), y_train)</span>
<span id="cb102-6"><a href="#cb102-6" aria-hidden="true" tabindex="-1"></a>y_pred_lin <span class="op">=</span> reg_lin.predict(x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span></code></pre></div>
</div>
<div id="c821f79e-01ca-415b-bb06-5627deacc956" class="cell code"
data-execution_count="167">
<div class="sourceCode" id="cb103"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="dv">81</span></span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>mse_lin <span class="op">=</span> []</span>
<span id="cb103-3"><a href="#cb103-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-4"><a href="#cb103-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the MSE value for the linear regression</span></span>
<span id="cb103-5"><a href="#cb103-5" aria-hidden="true" tabindex="-1"></a>mse_lin <span class="op">=</span> mean_squared_error(y_test, y_pred_lin)</span>
<span id="cb103-6"><a href="#cb103-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-7"><a href="#cb103-7" aria-hidden="true" tabindex="-1"></a><span class="co"># The MSE value calculated above is the same for all values of K. </span></span>
<span id="cb103-8"><a href="#cb103-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Therefore, we create an array storing that MSE value (k-1) many times.</span></span>
<span id="cb103-9"><a href="#cb103-9" aria-hidden="true" tabindex="-1"></a><span class="co"># This will later be used to plot the MSE value versus the number of nearest neighbors.</span></span>
<span id="cb103-10"><a href="#cb103-10" aria-hidden="true" tabindex="-1"></a>mse_lin <span class="op">=</span> [mse_lin]<span class="op">*</span>(k<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb103-11"><a href="#cb103-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-12"><a href="#cb103-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-13"><a href="#cb103-13" aria-hidden="true" tabindex="-1"></a>mse_knn <span class="op">=</span> []</span>
<span id="cb103-14"><a href="#cb103-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, k):</span>
<span id="cb103-15"><a href="#cb103-15" aria-hidden="true" tabindex="-1"></a>    reg_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors <span class="op">=</span> i)</span>
<span id="cb103-16"><a href="#cb103-16" aria-hidden="true" tabindex="-1"></a>    reg_knn.fit(x_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), y_train)</span>
<span id="cb103-17"><a href="#cb103-17" aria-hidden="true" tabindex="-1"></a>    y_pred_knn <span class="op">=</span> reg_knn.predict(x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb103-18"><a href="#cb103-18" aria-hidden="true" tabindex="-1"></a>    mse_knn.append(mean_squared_error(y_test, y_pred_knn))</span></code></pre></div>
</div>
<div id="86508b08-89a1-46cf-b0a6-b9239a0b1493" class="cell markdown">
<p>Now let's plot MSE vs Number of Neighbors</p>
</div>
<div id="c490e2a9-b747-40cf-b47f-90247481fc98" class="cell code"
data-execution_count="168">
<div class="sourceCode" id="cb104"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb104-2"><a href="#cb104-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-3"><a href="#cb104-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb104-4"><a href="#cb104-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-5"><a href="#cb104-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Since the linear regression is not affected by the value of K, the output is a straight line.</span></span>
<span id="cb104-6"><a href="#cb104-6" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, k)), </span>
<span id="cb104-7"><a href="#cb104-7" aria-hidden="true" tabindex="-1"></a>         mse_lin, </span>
<span id="cb104-8"><a href="#cb104-8" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;orange&#39;</span>, </span>
<span id="cb104-9"><a href="#cb104-9" aria-hidden="true" tabindex="-1"></a>         label <span class="op">=</span> <span class="st">&#39;linear&#39;</span>)</span>
<span id="cb104-10"><a href="#cb104-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-11"><a href="#cb104-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the MSE of the KNN regressions versus the value of K.</span></span>
<span id="cb104-12"><a href="#cb104-12" aria-hidden="true" tabindex="-1"></a>plt.plot(<span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">1</span>, k)), </span>
<span id="cb104-13"><a href="#cb104-13" aria-hidden="true" tabindex="-1"></a>         mse_knn, </span>
<span id="cb104-14"><a href="#cb104-14" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;red&#39;</span>, </span>
<span id="cb104-15"><a href="#cb104-15" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, </span>
<span id="cb104-16"><a href="#cb104-16" aria-hidden="true" tabindex="-1"></a>         markerfacecolor <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>,</span>
<span id="cb104-17"><a href="#cb104-17" aria-hidden="true" tabindex="-1"></a>         label <span class="op">=</span> <span class="st">&#39;KNN&#39;</span>)</span>
<span id="cb104-18"><a href="#cb104-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb104-19"><a href="#cb104-19" aria-hidden="true" tabindex="-1"></a>ax.legend(loc<span class="op">=</span><span class="st">&#39;lower right&#39;</span>)</span>
<span id="cb104-20"><a href="#cb104-20" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">&#39;Mean-Squared Error (MSE)&#39;</span>)</span>
<span id="cb104-21"><a href="#cb104-21" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">&#39;K&#39;</span>)</span>
<span id="cb104-22"><a href="#cb104-22" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">&#39;MSE&#39;</span>)</span>
<span id="cb104-23"><a href="#cb104-23" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/77be0ff1c1a3fc822067db38fb070d5776e54a3b.png" /></p>
</div>
</div>
<div id="8a24a0ee-64b0-42c7-9e4c-84cb3c33c920" class="cell markdown">
<p>KNN gives much better result as there is non linear relationship in
the data. Thus we can guess linear won't be a good fit here and that is
indeed the case.</p>
</div>
<div id="aedb39b4-37ae-41fd-946b-3e832e653cd3" class="cell code"
data-execution_count="169">
<div class="sourceCode" id="cb105"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list to store the predictions from 3 KNN regressions</span></span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>y_pred_knn <span class="op">=</span> []</span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create 3 KNN regressions with K = 1, 7, and 80.</span></span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> [<span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">80</span>]:</span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    reg_knn <span class="op">=</span> KNeighborsRegressor(n_neighbors <span class="op">=</span> i)</span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    reg_knn.fit(x_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), y_train)</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a>    y_pred_knn.append(reg_knn.predict(x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)))</span></code></pre></div>
</div>
<div id="16a1a138-d7c8-4c66-a518-ef8538dece7b" class="cell code"
data-execution_count="170">
<div class="sourceCode" id="cb106"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(data <span class="op">=</span> {<span class="st">&#39;x_test&#39;</span>:<span class="bu">list</span>(x_test.flatten()), </span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>                          <span class="st">&#39;y_test&#39;</span>:<span class="bu">list</span>(y_test.flatten()), </span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a>                          <span class="st">&#39;y_pred_lin&#39;</span>:<span class="bu">list</span>(y_pred_lin.flatten()), </span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>                          <span class="st">&#39;y_pred_knn-1&#39;</span>:<span class="bu">list</span>(y_pred_knn[<span class="dv">0</span>].flatten()), </span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>                          <span class="st">&#39;y_pred_knn-7&#39;</span>:<span class="bu">list</span>(y_pred_knn[<span class="dv">1</span>].flatten()), </span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>                          <span class="st">&#39;y_pred_knn-80&#39;</span>:<span class="bu">list</span>(y_pred_knn[<span class="dv">2</span>].flatten())})</span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.sort_values(by <span class="op">=</span> [<span class="st">&#39;x_test&#39;</span>])</span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>x_test_sorted <span class="op">=</span> df[<span class="st">&#39;x_test&#39;</span>].tolist()</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>y_test_sorted <span class="op">=</span> df[<span class="st">&#39;y_test&#39;</span>].tolist()</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a>y_pred_lin_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_lin&#39;</span>].tolist()</span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>y_pred_knn1_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn-1&#39;</span>].tolist()</span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>y_pred_knn7_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn-7&#39;</span>].tolist()</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>y_pred_knn80_sorted <span class="op">=</span> df[<span class="st">&#39;y_pred_knn-80&#39;</span>].tolist()</span></code></pre></div>
</div>
<div id="d91a9c29-8a13-4f5c-a386-92947e4d13cc" class="cell markdown">
<p>Plotting regression on top of test data</p>
</div>
<div id="e77ace37-c947-4d69-a4d5-39b2326c8216" class="cell code"
data-execution_count="171">
<div class="sourceCode" id="cb107"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>sns.<span class="bu">set</span>()</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">4</span>))</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a>ax1.scatter(x_test_sorted, </span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>            y_test_sorted, </span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test_sorted, </span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a>         y_pred_lin_sorted, </span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;orange&#39;</span>)</span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;Linear fit on top of the test data&#39;</span>)</span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb107-15"><a href="#cb107-15" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Target&#39;</span>)</span>
<span id="cb107-16"><a href="#cb107-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-17"><a href="#cb107-17" aria-hidden="true" tabindex="-1"></a>ax2.scatter(x_test_sorted, </span>
<span id="cb107-18"><a href="#cb107-18" aria-hidden="true" tabindex="-1"></a>            y_test_sorted, </span>
<span id="cb107-19"><a href="#cb107-19" aria-hidden="true" tabindex="-1"></a>            color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb107-20"><a href="#cb107-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-21"><a href="#cb107-21" aria-hidden="true" tabindex="-1"></a>ax2.plot(x_test_sorted, </span>
<span id="cb107-22"><a href="#cb107-22" aria-hidden="true" tabindex="-1"></a>         y_pred_knn7_sorted, </span>
<span id="cb107-23"><a href="#cb107-23" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;red&#39;</span>, </span>
<span id="cb107-24"><a href="#cb107-24" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, </span>
<span id="cb107-25"><a href="#cb107-25" aria-hidden="true" tabindex="-1"></a>         markerfacecolor <span class="op">=</span> <span class="st">&#39;yellow&#39;</span>)</span>
<span id="cb107-26"><a href="#cb107-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-27"><a href="#cb107-27" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;KNN fit on top of the test data (K = 7)&#39;</span>)</span>
<span id="cb107-28"><a href="#cb107-28" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb107-29"><a href="#cb107-29" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Target&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/2dc33a94d23233e1d0f48db6197815e813697e94.png" /></p>
</div>
</div>
<div id="ffc3efe2-2a9f-439a-887a-aba2d33f0b61" class="cell markdown">
<p>Plotting regression on top of noiseless data</p>
</div>
<div id="db15bc3f-8726-4d11-87f8-9956c337ba14" class="cell code"
data-execution_count="172">
<div class="sourceCode" id="cb108"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a>fig, (ax1,ax2, ax3) <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">5</span>))</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the noiseless data on all 3 figures</span></span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a>ax1.scatter(inputs_no_noise, target_no_noise, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>ax2.scatter(inputs_no_noise, target_no_noise, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>ax3.scatter(inputs_no_noise, target_no_noise, color <span class="op">=</span> <span class="st">&#39;#000C1F&#39;</span>)</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fit from a KNN regression (K = 1)</span></span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>ax1.plot(x_test_sorted, </span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>         y_pred_knn1_sorted, </span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, </span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a>         markerfacecolor <span class="op">=</span> <span class="st">&#39;yellow&#39;</span>)</span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a>ax1.set_title(<span class="st">&#39;K = 1&#39;</span>)</span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>ax1.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a>ax1.set_ylabel(<span class="st">&#39;Target&#39;</span>)</span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fit from a KNN regression (K = 7)</span></span>
<span id="cb108-19"><a href="#cb108-19" aria-hidden="true" tabindex="-1"></a>ax2.plot(x_test_sorted, </span>
<span id="cb108-20"><a href="#cb108-20" aria-hidden="true" tabindex="-1"></a>         y_pred_knn7_sorted, </span>
<span id="cb108-21"><a href="#cb108-21" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb108-22"><a href="#cb108-22" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, </span>
<span id="cb108-23"><a href="#cb108-23" aria-hidden="true" tabindex="-1"></a>         markerfacecolor <span class="op">=</span> <span class="st">&#39;yellow&#39;</span>)</span>
<span id="cb108-24"><a href="#cb108-24" aria-hidden="true" tabindex="-1"></a>ax2.set_title(<span class="st">&#39;K = 7&#39;</span>)</span>
<span id="cb108-25"><a href="#cb108-25" aria-hidden="true" tabindex="-1"></a>ax2.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb108-26"><a href="#cb108-26" aria-hidden="true" tabindex="-1"></a>ax2.set_ylabel(<span class="st">&#39;Target&#39;</span>)</span>
<span id="cb108-27"><a href="#cb108-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-28"><a href="#cb108-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the fit from a KNN regression (K = 80)</span></span>
<span id="cb108-29"><a href="#cb108-29" aria-hidden="true" tabindex="-1"></a>ax3.plot(x_test_sorted, </span>
<span id="cb108-30"><a href="#cb108-30" aria-hidden="true" tabindex="-1"></a>         y_pred_knn80_sorted, </span>
<span id="cb108-31"><a href="#cb108-31" aria-hidden="true" tabindex="-1"></a>         color <span class="op">=</span> <span class="st">&#39;red&#39;</span>,</span>
<span id="cb108-32"><a href="#cb108-32" aria-hidden="true" tabindex="-1"></a>         marker <span class="op">=</span> <span class="st">&#39;o&#39;</span>, </span>
<span id="cb108-33"><a href="#cb108-33" aria-hidden="true" tabindex="-1"></a>         markerfacecolor <span class="op">=</span> <span class="st">&#39;yellow&#39;</span>)</span>
<span id="cb108-34"><a href="#cb108-34" aria-hidden="true" tabindex="-1"></a>ax3.set_title(<span class="st">&#39;K = 80&#39;</span>)</span>
<span id="cb108-35"><a href="#cb108-35" aria-hidden="true" tabindex="-1"></a>ax3.set_xlabel(<span class="st">&#39;Feature&#39;</span>)</span>
<span id="cb108-36"><a href="#cb108-36" aria-hidden="true" tabindex="-1"></a>ax3.set_ylabel(<span class="st">&#39;Target&#39;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_9b1725b5215a457a91822757bff4fbf3/457a0462b04695792bcf977c14ac03f99f1c6a02.png" /></p>
</div>
</div>
<div id="be858131-4be0-44e6-b6ea-d7c632c2a709" class="cell markdown">
<p>Thus, KNN is better in scenarios when there is no linear relationship
observed.</p>
<hr />
</div>
<div id="e44fa015-4b14-4955-ad7a-9639192e71b6" class="cell markdown">
<h2 id="deciding-on-using-distance-metric"><strong>Deciding on using
Distance Metric</strong></h2>
</div>
<div id="d7a7d2ba-f234-4a86-af5a-8ccce4adfc4c" class="cell markdown">
<p>Let's revisit the Role of the <code>p</code> Parameter -</p>
<p>The distance metric used in KNN plays a critical role in how
neighbors are selected. The general formula for distance is defined by
the <strong>Minkowski metric</strong>, which can be written as:</p>
<p><span
class="math display">(|<em>x</em><sub>1</sub>−<em>x</em><sub>2</sub>|<sup><em>p</em></sup>+|<em>y</em><sub>1</sub>−<em>y</em><sub>2</sub>|<sup><em>p</em></sup>)<sup>1/<em>p</em></sup></span></p>
<p>By varying the value of <code>p</code>, we get different types of
distances:</p>
<ul>
<li>When <code>p = 1</code>, the formula becomes the Manhattan (or
taxicab) distance.</li>
<li>When <code>p = 2</code>, it becomes the familiar Euclidean
distance.</li>
<li>Higher values of <code>p</code> result in other forms of the
Minkowski distance, and as <code>p → ∞</code>, it approaches the
Chebyshev distance (which only considers the largest coordinate
difference).</li>
</ul>
<p>While Euclidean distance (<code>p = 2</code>) is common, it is not
always the best option for all datasets. Depending on the feature
distribution, scale, or clustering of data, other values of
<code>p</code> might offer better classification performance.</p>
<p>Instead of guessing which distance is optimal, we can automate this
choice.</p>
<h4 id="using-gridsearchcv-to-select-the-best-p">Using GridSearchCV to
select the best <code>p</code></h4>
<p>The process involves:</p>
<ol>
<li><strong>Setting up a parameter grid</strong> that includes multiple
values for <code>p</code> (e.g., from 1 to 5 using
<code>range(1,6)</code>).</li>
<li>Creating an instance of <code>GridSearchCV</code> with:
<ul>
<li>The <code>KNeighborsClassifier</code> as the model (estimator).</li>
<li>The defined parameter grid.</li>
<li>A scoring method such as accuracy.</li>
</ul></li>
<li><strong>Training multiple models</strong>, each with a different
<code>p</code> value, using cross-validation.</li>
<li>Choosing the best-performing model automatically by checking which
parameter configuration gave the highest cross-validation accuracy.</li>
</ol>
<p>So, instead of assuming a fixed distance metric, it's better to tune
<code>p</code> as a hyperparameter. GridSearchCV makes this easy by
systematically evaluating performance across a range of values. Using a
higher-order Minkowski distance might capture subtle relationships in
the data that simpler metrics miss. This approach ensures that the
distance function is <strong>tailored to data</strong>, potentially
leading to more accurate and robust predictions.</p>
<hr />
</div>
<div id="8a7d17b0-52e5-40e7-a729-af98d58685d7" class="cell markdown">
<h2 id="knn-pros-and-cons"><strong>KNN Pros and Cons</strong></h2>
</div>
<div id="e39c5694-874b-4240-9b88-e64dbf0c8185" class="cell markdown">
<h4 id="knn-classifier">KNN Classifier</h4>
<p><strong>Pros:</strong></p>
<ul>
<li>Simple and easy to understand.</li>
<li>No training phase; makes predictions directly using the training
data.</li>
<li>Naturally handles multi-class classification.</li>
<li>Effective when decision boundaries are irregular.</li>
<li>Flexible to feature types with appropriate distance metrics (e.g.,
Hamming for categorical).</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Computationally expensive at prediction time (especially with large
datasets).</li>
<li>Sensitive to the choice of distance metric and the value of k.</li>
<li>Poor performance on imbalanced datasets.</li>
<li>Affected by noisy data and irrelevant features.</li>
<li>Requires proper feature scaling (e.g., normalization or
standardization).</li>
</ul>
<hr />
<h4 id="knn-regressor">KNN Regressor</h4>
<p><strong>Pros:</strong></p>
<ul>
<li>Makes no assumption about the underlying data distribution.</li>
<li>Can model complex, non-linear relationships.</li>
<li>Easy to implement and intuitive.</li>
<li>Adapts well to local data patterns.</li>
<li>Performs well when the target function is smooth.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Struggles with extrapolation outside the training data range.</li>
<li>Sensitive to outliers in target values.</li>
<li>Requires large datasets to work effectively.</li>
<li>Slower predictions due to lack of training and full dataset
scanning.</li>
<li>Choice of k and feature scaling strongly impact performance.</li>
</ul>
<hr />
</div>
<div id="a9043f0f-3a80-4c74-a44a-a467f32e97e4" class="cell markdown">
<h4 id="knn-classifier-and-regressor--drawbacks">KNN Classifier and
Regressor – Drawbacks</h4>
<ol>
<li><p><strong>Computational cost during prediction</strong> Since KNN
stores the entire training dataset and performs calculations for each
prediction, it can be slow and inefficient, especially with large
datasets.</p></li>
<li><p><strong>Curse of dimensionality</strong> As the number of
features increases, the distance between data points becomes less
meaningful. This reduces the effectiveness of the algorithm and may lead
to poor performance in high-dimensional spaces.</p></li>
<li><p><strong>Limited suitability for categorical data</strong> KNN
struggles with purely categorical features unless special distance
metrics are applied. Standard Euclidean distance does not work well for
non-numeric data.</p></li>
<li><p><strong>Highly sensitive to irrelevant or noisy features</strong>
If the dataset contains unimportant or noisy features, they can distort
distance calculations and reduce prediction accuracy. Proper feature
selection or scaling is essential.</p></li>
<li><p><strong>Memory intensive</strong> Because KNN stores the entire
dataset, it can consume a lot of memory, especially for large training
sets.</p></li>
<li><p><strong>No model interpretation</strong> KNN does not provide an
explicit model or formula, so it lacks interpretability compared to
parametric methods like linear regression.</p></li>
<li><p><strong>Poor at extrapolation</strong> In regression tasks, KNN
cannot predict values outside the range of the training data, unlike
linear regression which can extend the fitted line.</p></li>
</ol>
</div>
</body>
</html>
